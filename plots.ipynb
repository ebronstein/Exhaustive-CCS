{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "from typing import Literal, Optional\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase figure size to (8, 8)\n",
    "rcParams[\"figure.figsize\"] = (10, 6)\n",
    "rcParams[\"figure.dpi\"] = 150\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = Path(\"extraction_results\")\n",
    "DEBERTA = \"deberta-v2-xxlarge-mnli\"\n",
    "\n",
    "DATASET_ORDER = (\"imdb\", \"amazon-polarity\", \"ag-news\", \"dbpedia-14\", \"copa\", \"rte\", \"boolq\", \"qnli\", \"piqa\", \"all\")\n",
    "METHOD_ORDER = (\"CCS\", \"LR\", \"CCS-md\", \"LR-md\", \"RCCS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_probs(\n",
    "    model_name: str,\n",
    "    train: str,\n",
    "    test: str,\n",
    "    method: str = \"CCS\",\n",
    "    save_dir: Optional[Path] = None,\n",
    "):\n",
    "    save_dir = save_dir or SAVE_DIR\n",
    "\n",
    "    dir = (save_dir / \"rccs\") if method.startswith(\"RCCS\") else save_dir\n",
    "    folder = dir / f\"states_{model_name}_{method}\" / train\n",
    "    pattern = f\"{test}*_{method}.csv\" if test != \"all\" else f\"*_{method}.csv\"\n",
    "    return pd.concat([pd.read_csv(f) for f in folder.glob(pattern)])\n",
    "\n",
    "\n",
    "def get_max_acc_df(df):\n",
    "    \"\"\"Compute max(acc, 1-acc) for each experiment.\n",
    "\n",
    "    Use the in-domain accuracy to decide whether to flip the accuracy instead of\n",
    "    computing max(acc, 1-acc) for test datasets even if the in-domain accuracy\n",
    "    is greater than 0.5.\n",
    "    \"\"\"\n",
    "    processed_df = []\n",
    "    for key, exp_df in df.groupby([\"model\", \"prefix\", \"method\", \"prompt_level\"]):\n",
    "        for train_ds in exp_df[\"train\"].unique():\n",
    "            train_df = exp_df[exp_df[\"train\"] == train_ds].copy()\n",
    "            if train_ds == \"all\":\n",
    "                # If trained on all the datasets, use the mean accuracy on each\n",
    "                # dataset to decide whether to flip the accuracy.\n",
    "                in_domain_acc = train_df[\"accuracy\"].mean()\n",
    "            else:\n",
    "                in_domain_acc = train_df[train_df[\"test\"] == train_ds][\"accuracy\"]\n",
    "                assert len(in_domain_acc) == 1\n",
    "                in_domain_acc = in_domain_acc.iloc[0]\n",
    "            if in_domain_acc < 0.5:\n",
    "                print(f\"Flipping accuracy for {key} {train_ds}\")\n",
    "                train_df[\"accuracy\"] = 1 - train_df[\"accuracy\"]\n",
    "\n",
    "            processed_df.append(train_df)\n",
    "    return pd.concat(processed_df)\n",
    "\n",
    "\n",
    "def load_stats_dfs(\n",
    "    model_name: str,\n",
    "    train: Optional[str] = None,\n",
    "    test: Optional[str] = None,\n",
    "    method: Optional[str] = None,\n",
    "    prefix: Optional[str] = None,\n",
    "    save_dir: Optional[Path] = None,\n",
    "    max_acc: bool = True,\n",
    "):\n",
    "    save_dir = save_dir or SAVE_DIR\n",
    "\n",
    "    if method is not None and method.startswith(\"RCCS\"):\n",
    "        dir = save_dir / \"rccs\"\n",
    "    else:\n",
    "        dir = save_dir\n",
    "\n",
    "    if prefix is None:\n",
    "        pattern = f\"{model_name}*.csv\"\n",
    "    else:\n",
    "        pattern = f\"{model_name}_{prefix}_*.csv\"\n",
    "    csvs = dir.glob(pattern)\n",
    "    dfs = [pd.read_csv(f) for f in csvs]\n",
    "\n",
    "    if not dfs:\n",
    "        raise ValueError(\n",
    "            f\"No csvs found for {model_name}, {train}, {test}, {method}\"\n",
    "        )\n",
    "\n",
    "    # Filter by train & method\n",
    "    if train is not None and train != \"all\":\n",
    "        dfs = [df[df[\"train\"] == train] for df in dfs]\n",
    "    if method is not None:\n",
    "        dfs = [df[df[\"method\"] == method] for df in dfs]\n",
    "\n",
    "    if test is not None and test != \"all\":\n",
    "        # Filter by test\n",
    "        dfs = [df[df[\"test\"] == test] for df in dfs]\n",
    "        assert all(len(df) == 1 for df in dfs)\n",
    "\n",
    "    if max_acc:\n",
    "        dfs = [get_max_acc_df(df) for df in dfs]\n",
    "\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def load_stats(\n",
    "    model_name: str,\n",
    "    train: str,\n",
    "    test: str,\n",
    "    method: str,\n",
    "    prefix: str,\n",
    "    save_dir: Optional[Path] = None,\n",
    "):\n",
    "    dfs = load_stats_dfs(model_name, train, test, method, prefix, save_dir=save_dir)\n",
    "    # If test = \"all\", average across all test datasets for each seed.\n",
    "    # Otherwise, return the stats for the single test dataset for each seed.\n",
    "    return {\n",
    "        k: np.array([df[k].mean() for df in dfs])\n",
    "        for k in [\"accuracy\", \"loss\", \"cons_loss\", \"sim_loss\"]\n",
    "        if all(k in df.columns for df in dfs)\n",
    "    }  # k: (seeds,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dfs = load_stats_dfs(DEBERTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"normal\"\n",
    "std_annot = False\n",
    "\n",
    "# Filter DataFrames to only include rows with prefix \"normal\"\n",
    "filtered_data = []\n",
    "for df in stats_dfs:\n",
    "    prefix_df = df[df[\"prefix\"] == prefix]\n",
    "    if not prefix_df.empty:\n",
    "        filtered_data.append(prefix_df)\n",
    "\n",
    "# Combine filtered DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(filtered_data, ignore_index=True)\n",
    "\n",
    "# Calculate mean accuracy and standard deviation of accuracy for each combination\n",
    "agg_df = combined_df.groupby(['model', 'method', 'train', 'test']).agg(\n",
    "    mean_accuracy=('accuracy', 'mean'),\n",
    "    std_accuracy=('accuracy', 'std')\n",
    ").reset_index()\n",
    "\n",
    "for model in agg_df.model.unique():\n",
    "    model_df = agg_df[agg_df['model'] == model]\n",
    "    for method in METHOD_ORDER:\n",
    "        df = model_df[model_df['method'] == method]\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "\n",
    "        # Modify the pivot table creation to include both mean accuracy and std accuracy in the annotations\n",
    "        pivot_table_mean = df.pivot(\"train\", \"test\", \"mean_accuracy\").reindex(index=DATASET_ORDER, columns=DATASET_ORDER)\n",
    "        pivot_table_std = df.pivot(\"train\", \"test\", \"std_accuracy\").reindex(index=DATASET_ORDER, columns=DATASET_ORDER)\n",
    "\n",
    "        # Reorder the pivot tables according to DATASET_ORDER\n",
    "        pivot_table_mean_ordered = pivot_table_mean.reindex(index=DATASET_ORDER, columns=DATASET_ORDER)\n",
    "        pivot_table_std_ordered = pivot_table_std.reindex(index=DATASET_ORDER, columns=DATASET_ORDER)\n",
    "\n",
    "        # Combine mean and std into a single string for each cell annotation\n",
    "        annotations = pivot_table_mean.applymap(\"{:.2f}\".format)\n",
    "        if std_annot:\n",
    "            annotations += \"+-\" + pivot_table_std.applymap(\"{:.2f}\".format)\n",
    "            annot_size = 6\n",
    "        else:\n",
    "            annot_size = 10\n",
    "\n",
    "        # Create the heatmap with custom annotations\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(pivot_table_mean, annot=annotations, fmt=\"\", cmap=\"viridis\",\n",
    "                    cbar_kws={'label': 'Mean Accuracy'}, vmin=0.5, vmax=1, annot_kws={\"size\": annot_size})\n",
    "\n",
    "        # Adding title and axis labels\n",
    "        plt.title(f'{model} - {method} Mean Accuracy')\n",
    "        plt.xlabel('Test Dataset')\n",
    "        plt.ylabel('Train Dataset')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deberta-v2-xxlarge-mnli</td>\n",
       "      <td>CCS</td>\n",
       "      <td>ag-news</td>\n",
       "      <td>ag-news</td>\n",
       "      <td>0.889594</td>\n",
       "      <td>0.011566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deberta-v2-xxlarge-mnli</td>\n",
       "      <td>CCS</td>\n",
       "      <td>ag-news</td>\n",
       "      <td>amazon-polarity</td>\n",
       "      <td>0.821023</td>\n",
       "      <td>0.043104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deberta-v2-xxlarge-mnli</td>\n",
       "      <td>CCS</td>\n",
       "      <td>ag-news</td>\n",
       "      <td>boolq</td>\n",
       "      <td>0.660775</td>\n",
       "      <td>0.018843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deberta-v2-xxlarge-mnli</td>\n",
       "      <td>CCS</td>\n",
       "      <td>ag-news</td>\n",
       "      <td>copa</td>\n",
       "      <td>0.546167</td>\n",
       "      <td>0.007097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deberta-v2-xxlarge-mnli</td>\n",
       "      <td>CCS</td>\n",
       "      <td>ag-news</td>\n",
       "      <td>dbpedia-14</td>\n",
       "      <td>0.964125</td>\n",
       "      <td>0.003495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>deberta-v2-xxlarge-mnli</td>\n",
       "      <td>CCS</td>\n",
       "      <td>rte</td>\n",
       "      <td>dbpedia-14</td>\n",
       "      <td>0.645031</td>\n",
       "      <td>0.032496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>deberta-v2-xxlarge-mnli</td>\n",
       "      <td>CCS</td>\n",
       "      <td>rte</td>\n",
       "      <td>imdb</td>\n",
       "      <td>0.621442</td>\n",
       "      <td>0.017998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>deberta-v2-xxlarge-mnli</td>\n",
       "      <td>CCS</td>\n",
       "      <td>rte</td>\n",
       "      <td>piqa</td>\n",
       "      <td>0.539841</td>\n",
       "      <td>0.008679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>deberta-v2-xxlarge-mnli</td>\n",
       "      <td>CCS</td>\n",
       "      <td>rte</td>\n",
       "      <td>qnli</td>\n",
       "      <td>0.638950</td>\n",
       "      <td>0.010866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>deberta-v2-xxlarge-mnli</td>\n",
       "      <td>CCS</td>\n",
       "      <td>rte</td>\n",
       "      <td>rte</td>\n",
       "      <td>0.833068</td>\n",
       "      <td>0.008028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model method    train             test  mean_accuracy  \\\n",
       "0   deberta-v2-xxlarge-mnli    CCS  ag-news          ag-news       0.889594   \n",
       "1   deberta-v2-xxlarge-mnli    CCS  ag-news  amazon-polarity       0.821023   \n",
       "2   deberta-v2-xxlarge-mnli    CCS  ag-news            boolq       0.660775   \n",
       "3   deberta-v2-xxlarge-mnli    CCS  ag-news             copa       0.546167   \n",
       "4   deberta-v2-xxlarge-mnli    CCS  ag-news       dbpedia-14       0.964125   \n",
       "..                      ...    ...      ...              ...            ...   \n",
       "85  deberta-v2-xxlarge-mnli    CCS      rte       dbpedia-14       0.645031   \n",
       "86  deberta-v2-xxlarge-mnli    CCS      rte             imdb       0.621442   \n",
       "87  deberta-v2-xxlarge-mnli    CCS      rte             piqa       0.539841   \n",
       "88  deberta-v2-xxlarge-mnli    CCS      rte             qnli       0.638950   \n",
       "89  deberta-v2-xxlarge-mnli    CCS      rte              rte       0.833068   \n",
       "\n",
       "    std_accuracy  \n",
       "0       0.011566  \n",
       "1       0.043104  \n",
       "2       0.018843  \n",
       "3       0.007097  \n",
       "4       0.003495  \n",
       "..           ...  \n",
       "85      0.032496  \n",
       "86      0.017998  \n",
       "87      0.008679  \n",
       "88      0.010866  \n",
       "89      0.008028  \n",
       "\n",
       "[90 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df[agg_df[\"method\"] == \"CCS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict = load_stats(DEBERTA, \"imdb\", \"all\", \"CCS\", \"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': array([0.73433219, 0.73827072, 0.73210774, 0.73512759, 0.73495521,\n",
       "        0.73751971, 0.7392942 , 0.73676192, 0.73923347, 0.73621103]),\n",
       " 'loss': array([0.48174268, 0.49184621, 0.48894357, 0.50459721, 0.46131563,\n",
       "        0.50674405, 0.50379212, 0.48608973, 0.48088501, 0.48863824]),\n",
       " 'cons_loss': array([0.17713956, 0.17177885, 0.17801163, 0.18261436, 0.17174362,\n",
       "        0.18504469, 0.18097273, 0.17447856, 0.17481037, 0.17436141]),\n",
       " 'sim_loss': array([0.30460312, 0.32006736, 0.31093193, 0.32198284, 0.28957201,\n",
       "        0.32169935, 0.3228194 , 0.31161117, 0.30607464, 0.31427682])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"extraction_results/deberta-v2-xxlarge-mnli_normal-dot_0.csv\"\n",
    "df = pd.read_csv(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['all', 'imdb', 'amazon-polarity', 'ag-news', 'dbpedia-14', 'copa',\n",
       "       'rte', 'boolq', 'qnli', 'piqa'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ag-news', 'ag-news'),\n",
       " ('ag-news', 'amazon-polarity'),\n",
       " ('ag-news', 'boolq'),\n",
       " ('ag-news', 'copa'),\n",
       " ('ag-news', 'dbpedia-14'),\n",
       " ('ag-news', 'imdb'),\n",
       " ('ag-news', 'piqa'),\n",
       " ('ag-news', 'qnli'),\n",
       " ('ag-news', 'rte'),\n",
       " ('all', 'ag-news'),\n",
       " ('all', 'amazon-polarity'),\n",
       " ('all', 'boolq'),\n",
       " ('all', 'copa'),\n",
       " ('all', 'dbpedia-14'),\n",
       " ('all', 'imdb'),\n",
       " ('all', 'piqa'),\n",
       " ('all', 'qnli'),\n",
       " ('all', 'rte'),\n",
       " ('amazon-polarity', 'ag-news'),\n",
       " ('amazon-polarity', 'amazon-polarity'),\n",
       " ('amazon-polarity', 'boolq'),\n",
       " ('amazon-polarity', 'copa'),\n",
       " ('amazon-polarity', 'dbpedia-14'),\n",
       " ('amazon-polarity', 'imdb'),\n",
       " ('amazon-polarity', 'piqa'),\n",
       " ('amazon-polarity', 'qnli'),\n",
       " ('amazon-polarity', 'rte'),\n",
       " ('boolq', 'ag-news'),\n",
       " ('boolq', 'amazon-polarity'),\n",
       " ('boolq', 'boolq'),\n",
       " ('boolq', 'copa'),\n",
       " ('boolq', 'dbpedia-14'),\n",
       " ('boolq', 'imdb'),\n",
       " ('boolq', 'piqa'),\n",
       " ('boolq', 'qnli'),\n",
       " ('boolq', 'rte'),\n",
       " ('copa', 'ag-news'),\n",
       " ('copa', 'amazon-polarity'),\n",
       " ('copa', 'boolq'),\n",
       " ('copa', 'copa'),\n",
       " ('copa', 'dbpedia-14'),\n",
       " ('copa', 'imdb'),\n",
       " ('copa', 'piqa'),\n",
       " ('copa', 'qnli'),\n",
       " ('copa', 'rte'),\n",
       " ('dbpedia-14', 'ag-news'),\n",
       " ('dbpedia-14', 'amazon-polarity'),\n",
       " ('dbpedia-14', 'boolq'),\n",
       " ('dbpedia-14', 'copa'),\n",
       " ('dbpedia-14', 'dbpedia-14'),\n",
       " ('dbpedia-14', 'imdb'),\n",
       " ('dbpedia-14', 'piqa'),\n",
       " ('dbpedia-14', 'qnli'),\n",
       " ('dbpedia-14', 'rte'),\n",
       " ('imdb', 'ag-news'),\n",
       " ('imdb', 'amazon-polarity'),\n",
       " ('imdb', 'boolq'),\n",
       " ('imdb', 'copa'),\n",
       " ('imdb', 'dbpedia-14'),\n",
       " ('imdb', 'imdb'),\n",
       " ('imdb', 'piqa'),\n",
       " ('imdb', 'qnli'),\n",
       " ('imdb', 'rte'),\n",
       " ('piqa', 'ag-news'),\n",
       " ('piqa', 'amazon-polarity'),\n",
       " ('piqa', 'boolq'),\n",
       " ('piqa', 'copa'),\n",
       " ('piqa', 'dbpedia-14'),\n",
       " ('piqa', 'imdb'),\n",
       " ('piqa', 'piqa'),\n",
       " ('piqa', 'qnli'),\n",
       " ('piqa', 'rte'),\n",
       " ('qnli', 'ag-news'),\n",
       " ('qnli', 'amazon-polarity'),\n",
       " ('qnli', 'boolq'),\n",
       " ('qnli', 'copa'),\n",
       " ('qnli', 'dbpedia-14'),\n",
       " ('qnli', 'imdb'),\n",
       " ('qnli', 'piqa'),\n",
       " ('qnli', 'qnli'),\n",
       " ('qnli', 'rte'),\n",
       " ('rte', 'ag-news'),\n",
       " ('rte', 'amazon-polarity'),\n",
       " ('rte', 'boolq'),\n",
       " ('rte', 'copa'),\n",
       " ('rte', 'dbpedia-14'),\n",
       " ('rte', 'imdb'),\n",
       " ('rte', 'piqa'),\n",
       " ('rte', 'qnli'),\n",
       " ('rte', 'rte')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_list = []\n",
    "for i in range(len(df)):\n",
    "    train_test_list.append((df.iloc[i]['train'], df.iloc[i]['test']))\n",
    "\n",
    "test_test_sets = sorted(set(train_test_list))\n",
    "test_test_sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exhaustive_ccs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
